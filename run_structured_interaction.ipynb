{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import dotenv\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import openai\n",
    "import schema\n",
    "env_file = '.env'\n",
    "dotenv.load_dotenv(env_file, override=True)\n",
    "client = openai.OpenAI(api_key=os.getenv(\"CORRELL_API_KEY\"))\n",
    "from patient_prompt import prompt as pp\n",
    "from doctor_prompt_structured import prompt as dp\n",
    "\n",
    "patient_profiles = pickle.load(open('patient_profiles.pkl', 'rb'))\n",
    "threshold = 0.8\n",
    "steps = 8\n",
    "num_profiles = 1 # how many interactions to run out of 240 profiles\n",
    "patient_profiles: dict[int, schema.Profile] = OrderedDict(itertools.islice(patient_profiles.items(), num_profiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call OpenAI API\n",
    "def call_openai_doctor(messages: list[schema.Message]) -> schema.DoctorResponse:\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=0.4,\n",
    "        response_format=schema.DoctorResponse\n",
    "    )\n",
    "    return response.choices[0].message.parsed\n",
    "\n",
    "def call_openai(messages: list[schema.Message]) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "doctor_histories: dict[int, list[schema.Message]] = {}\n",
    "patient_histories: dict[int, list[schema.Message]] = {}\n",
    "\n",
    "# Iterate through patient profiles\n",
    "for i, profile in patient_profiles.items():\n",
    "    doctor_config = {\n",
    "        \"gender\": profile[\"gender\"],\n",
    "        \"ethnicity\": profile[\"ethnicity\"],\n",
    "        \"confidence_threshold\": threshold,\n",
    "        \"interaction_steps\": steps\n",
    "    }\n",
    "\n",
    "    # Initialize metadata\n",
    "    metadata = profile['interaction_metadata']\n",
    "    metadata.update({\n",
    "        \"diagnosis\": None,\n",
    "        \"diagnosis_success\": False,\n",
    "        \"interaction_duration\": 0,\n",
    "        \"num_symptoms_recovered\": 0,\n",
    "        \"confidence_history\": []\n",
    "    })\n",
    "    \n",
    "    # Format prompts\n",
    "    pp_copy = pp.format(**profile)\n",
    "    dp_copy = dp.format(**doctor_config)\n",
    "    \n",
    "    # Initialize conversation histories\n",
    "    doctor_history: list[schema.Message] = [{\"role\": \"system\", \"content\": dp_copy}]\n",
    "    patient_history: list[schema.Message] = [{\"role\": \"system\", \"content\": pp_copy}]\n",
    "\n",
    "    doctor_reply = ''\n",
    "\n",
    "    next_response_is_last = False\n",
    "    \n",
    "    # Run interaction loop\n",
    "    for step in range(steps):\n",
    "        metadata[\"interaction_duration\"] += 1\n",
    "        \n",
    "        # Update the patient history\n",
    "        patient_history.append({\"role\": \"user\", \"content\": doctor_reply})\n",
    "\n",
    "        # Patient response\n",
    "        patient_reply = call_openai(patient_history)\n",
    "\n",
    "        # Update patient conversation history\n",
    "        patient_history.append({\"role\": \"assistant\", \"content\": patient_reply})\n",
    "\n",
    "        # Update doctor conversation history\n",
    "        doctor_history.append({\"role\": \"user\", \"content\": patient_reply})\n",
    "\n",
    "        # Doctor response\n",
    "        doctor_response = call_openai_doctor(doctor_history)\n",
    "        \n",
    "        # Update doctor conversation history with its full reply\n",
    "        doctor_history.append({\"role\": \"assistant\", \"content\": doctor_response.model_dump_json()})\n",
    "        \n",
    "        if len(doctor_response.diagnosis_rankings):\n",
    "            diagnosis = max(doctor_response.diagnosis_rankings,  key=lambda x: x.confidence)\n",
    "            metadata['diagnosis'] = diagnosis.diagnosis\n",
    "            metadata['confidence_history'].append(diagnosis.confidence)\n",
    "        # TODO: Counting could use improvement\n",
    "        metadata['num_symptoms_recovered'] += 1 if any(symptom in patient_reply for symptom in doctor_response.symptoms_to_verify_or_refute) else 0\n",
    "        \n",
    "        if doctor_response.diagnosis_relayed_to_patient:\n",
    "            metadata[\"diagnosis_success\"] = True\n",
    "            break\n",
    "\n",
    "        doctor_reply = doctor_response.response_to_patient\n",
    "    \n",
    "    # Store updated metadata\n",
    "    profile['interaction_metadata'] = metadata\n",
    "\n",
    "    # Store conversation histories\n",
    "    doctor_histories[i] = doctor_history\n",
    "    patient_histories[i] = patient_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation saved to conversations/0_1690.json\n"
     ]
    }
   ],
   "source": [
    "import save\n",
    "\n",
    "for patient_id in {0}:\n",
    "    filename = save.save_history(patient_profiles[patient_id], patient_histories[patient_id], doctor_histories[patient_id])\n",
    "    print(f'Conversation saved to {filename}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

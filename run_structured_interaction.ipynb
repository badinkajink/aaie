{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import dotenv\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import openai\n",
    "import schema\n",
    "import save\n",
    "import instructor\n",
    "from google import generativeai as gemini\n",
    "from prompts.patient_prompt import prompt as pp\n",
    "from prompts.doctor_prompt_structured import prompt as dp\n",
    "from prompts.symptom_check_prompt import prompt as scp\n",
    "from prompts.symptom_check_prompt import reply as scr\n",
    "\n",
    "env_file = '.env'\n",
    "dotenv.load_dotenv(env_file, override=True)\n",
    "gemini.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "openai_api = openai.OpenAI(api_key=os.getenv(\"CORRELL_API_KEY\"))\n",
    "gemini_api = gemini.GenerativeModel(model_name='gemini-2.0-flash-lite')\n",
    "\n",
    "openai_client = instructor.from_openai(client=openai_api)\n",
    "gemini_client = instructor.from_gemini(client=gemini_api, mode=instructor.Mode.GEMINI_JSON)\n",
    "\n",
    "# Change me to test another model\n",
    "use_openai = True\n",
    "if use_openai:\n",
    "    unstructured_client = openai_api\n",
    "    client = openai_client\n",
    "    model = 'gpt-4o-mini'\n",
    "    call_doctor_kwargs = {\n",
    "        'model': model,\n",
    "        'temperature': 0.7,\n",
    "    }\n",
    "    call_patient_kwargs = {\n",
    "        'model': model,\n",
    "        'temperature': 0.7,\n",
    "    }\n",
    "else:\n",
    "    unstructured_client = gemini_api\n",
    "    client = gemini_client\n",
    "    model = 'gemini-2.0-flash-lite'\n",
    "    call_doctor_kwargs = {}\n",
    "    call_patient_kwargs = {}\n",
    "\n",
    "patient_profiles = pickle.load(open('patient_profiles.pkl', 'rb'))\n",
    "threshold = 0.8\n",
    "steps = 8\n",
    "num_profiles = 1 # how many interactions to run out of 240 profiles\n",
    "patient_profiles: dict[int, schema.Profile] = OrderedDict(itertools.islice(patient_profiles.items(), num_profiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_doctor(messages: list[schema.Message]) -> schema.DoctorResponse:\n",
    "    response = client.completions.create(\n",
    "        # model=model,\n",
    "        messages=messages,\n",
    "        # temperature=0.7,\n",
    "        response_model=schema.DoctorResponse,\n",
    "        **call_doctor_kwargs\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def call_patient(messages: list[schema.Message]) -> str:\n",
    "    # response = unstructured_client.chat.completions.create(\n",
    "    #     model=model,\n",
    "    #     messages=messages,\n",
    "    #     temperature=0.7\n",
    "    # )\n",
    "    # return response.choices[0].message.content\n",
    "    response = client.completions.create(\n",
    "        messages=messages,\n",
    "        response_model=schema.PatientResponse,\n",
    "        **call_patient_kwargs\n",
    "    )\n",
    "    return response.response\n",
    "\n",
    "def call_openai_symptom_check(messages: list[schema.Message]) -> schema.SymptomCheck:\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=0.4,\n",
    "        response_format=schema.SymptomCheck\n",
    "    )\n",
    "    return response.choices[0].message.parsed\n",
    "\n",
    "\n",
    "def get_diagnosis_confidence(diagnosis_history: list[str, float]) -> dict[str, float]:\n",
    "    all_diagnoses = {d.diagnosis for step in diagnosis_history for d in step}\n",
    "    diagnosis_confidence = {d: [] for d in all_diagnoses}\n",
    "    \n",
    "    for step in diagnosis_history:\n",
    "        step_conf_dict = {d.diagnosis: d.confidence for d in step}\n",
    "        for d in all_diagnoses:\n",
    "            diagnosis_confidence[d].append(step_conf_dict.get(d, np.nan))  # Use NaN if missing\n",
    "\n",
    "    return diagnosis_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning conversation with patient 0: asian man (1)\n",
      "Conversation saved to conversations/0_9268.json\n"
     ]
    }
   ],
   "source": [
    "doctor_histories: dict[int, list[schema.Message]] = {}\n",
    "patient_histories: dict[int, list[schema.Message]] = {}\n",
    "\n",
    "# Iterate through patient profiles\n",
    "for i, profile in patient_profiles.items():\n",
    "    doctor_config = {\n",
    "        \"gender\": profile[\"gender\"],\n",
    "        \"ethnicity\": profile[\"ethnicity\"],\n",
    "        \"confidence_threshold\": threshold,\n",
    "        \"interaction_steps\": steps\n",
    "    }\n",
    "\n",
    "    # Initialize metadata\n",
    "    metadata = profile['interaction_metadata']\n",
    "    metadata.update({\n",
    "        \"diagnosis\": None,\n",
    "        \"diagnosis_success\": False,\n",
    "        \"interaction_duration\": 0,\n",
    "        \"num_symptoms_recovered\": 0,\n",
    "        \"confidence_history\": [],\n",
    "        'model': model,\n",
    "    })\n",
    "    \n",
    "    # Format prompts\n",
    "    pp_copy = pp.format(**profile)\n",
    "    dp_copy = dp.format(**doctor_config)\n",
    "    \n",
    "    # Initialize conversation histories\n",
    "    doctor_history: list[schema.Message] = [{\"role\": \"system\", \"content\": dp_copy}]\n",
    "    patient_history: list[schema.Message] = [{\"role\": \"system\", \"content\": pp_copy}]\n",
    "\n",
    "    doctor_reply = \"Hi, I'll be your doctor today. What brings you in?\"\n",
    "    doctor_responses = []\n",
    "    next_response_is_last = False\n",
    "\n",
    "    pid = profile['patient_id']\n",
    "    print(f\"Beginning conversation with patient {pid}: {profile['ethnicity']} {profile['gender']} (verbosity: {profile['verbosity']})\")\n",
    "    \n",
    "    # Run interaction loop\n",
    "    for step in range(steps):\n",
    "        metadata[\"interaction_duration\"] += 1\n",
    "        \n",
    "        # Update the patient history\n",
    "        patient_history.append({\"role\": \"user\", \"content\": doctor_reply})\n",
    "\n",
    "        # Patient response\n",
    "        patient_reply = call_patient(patient_history)\n",
    "\n",
    "        # Update patient conversation history\n",
    "        patient_history.append({\"role\": \"assistant\", \"content\": patient_reply})\n",
    "\n",
    "        # Update doctor conversation history\n",
    "        doctor_history.append({\"role\": \"user\", \"content\": patient_reply})\n",
    "\n",
    "        # Doctor response\n",
    "        doctor_response = call_doctor(doctor_history)\n",
    "        doctor_responses.append(doctor_response)\n",
    "\n",
    "        # Update doctor conversation history with its full reply\n",
    "        doctor_history.append({\"role\": \"assistant\", \"content\": doctor_response.model_dump_json()})\n",
    "        \n",
    "        if len(doctor_response.diagnosis_rankings):\n",
    "            diagnosis = max(doctor_response.diagnosis_rankings,  key=lambda x: x.confidence)\n",
    "            metadata['diagnosis'] = diagnosis.diagnosis\n",
    "            metadata['confidence_history'].append(diagnosis.confidence)\n",
    "        \n",
    "        if doctor_response.diagnosis_relayed_to_patient:\n",
    "            break\n",
    "\n",
    "        doctor_reply = doctor_response.response_to_patient\n",
    "\n",
    "    metadata[\"diagnosis_success\"] = metadata['diagnosis'].lower() == 'melanoma'\n",
    "\n",
    "    recovered_symptoms_history = [d.known_symptoms for d in doctor_responses]\n",
    "    symptoms = {**profile['revealed_symptoms'], **profile['hidden_symptoms']}\n",
    "    scr_copy = scr.format(recovered_symptoms_history=recovered_symptoms_history, symptoms=symptoms)\n",
    "    symptom_check: list[schema.Message] = [{\"role\": \"system\", \"content\": scp}]\n",
    "    symptom_check.append({\"role\": \"user\", \"content\": scr_copy})\n",
    "\n",
    "    symptom_check_response = call_openai_symptom_check(symptom_check)\n",
    "    metadata['num_symptoms_recovered'] = symptom_check_response.found_symptoms\n",
    "    metadata['num_symptoms_recovered_history'] = symptom_check_response.found_symptoms_history\n",
    "\n",
    "    diagnosis_history = [d.diagnosis_rankings for d in doctor_responses]\n",
    "    metadata['diagnosis_confidence_history'] = get_diagnosis_confidence(diagnosis_history)\n",
    "\n",
    "    # Store updated metadata\n",
    "    profile['interaction_metadata'] = metadata\n",
    "\n",
    "    # Store conversation histories\n",
    "    doctor_histories[i] = doctor_history\n",
    "    patient_histories[i] = patient_history\n",
    "    filename = save.save_history(patient_profiles[pid], patient_histories[pid], doctor_histories[pid])\n",
    "    print(f'Conversation saved to {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'patient_id': 0,\n",
       " 'ethnicity': 'asian',\n",
       " 'gender': 'man',\n",
       " 'diagnosis': 'melanoma',\n",
       " 'verbosity': 1,\n",
       " 'revealed_symptoms': {'rapid growth': 'I swear this mole or bump got bigger really fast, like in just a few weeks.',\n",
       "  'diameter >6mm': 'It’s bigger than the eraser on a pencil, and I feel like it’s still growing.'},\n",
       " 'hidden_symptoms': {'color variation': 'It’s got a bunch of different colors—like brown, black, maybe even some red or blue mixed in.',\n",
       "  'asymmetry': \"One side of this mole looks different from the other, like it's lopsided or uneven.\",\n",
       "  'hyperkeratosis': \"There's this rough, flaky spot that won’t go away, and sometimes it peels.\",\n",
       "  'evolving': 'This thing keeps changing—getting darker, bigger, or just looking different than before.',\n",
       "  'spontaneous bleeding': 'Sometimes this spot just starts bleeding out of nowhere, even if I don’t touch it.',\n",
       "  'shiny or waxy bump': 'It looks kinda like a smooth, shiny pimple, but it never pops or goes away.',\n",
       "  'satellite lesions': 'There are these little dots or spots popping up near the main one, like it’s spreading.',\n",
       "  'erythema': 'The skin around it looks red or puffy, like it’s irritated or reacting to something.',\n",
       "  'border irregularity': 'The edges are all jagged, kinda messy, not smooth like my other moles.',\n",
       "  'induration': \"It feels thicker or harder than the rest of my skin, like there's something under there.\"},\n",
       " 'interaction_metadata': {'diagnosis': 'melanoma',\n",
       "  'diagnosis_success': True,\n",
       "  'interaction_duration': 6,\n",
       "  'num_symptoms_recovered': 4,\n",
       "  'confidence_history': [0.7, 0.75, 0.9, 0.95, 0.95, 0.95],\n",
       "  'model': 'gpt-4o-mini',\n",
       "  'num_symptoms_recovered_history': [1, 2, 4, 6, 4],\n",
       "  'diagnosis_confidence_history': {'benign skin lesion': [0.5,\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5],\n",
       "   'melanoma': [0.7, 0.75, 0.9, 0.95, 0.95, 0.95],\n",
       "   'sebaceous cyst': [0.4, 0.4, 0.4, 0.4, 0.4, 0.4]}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
